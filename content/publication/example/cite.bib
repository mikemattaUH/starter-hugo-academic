@article{matta_evaluating_2022,
	title = {Evaluating validity and bias for hand-calculated and automated written expression curriculum-based measurement scores},
	volume = {29},
	issn = {0969-594X, 1465-329X},
	url = {https://www.tandfonline.com/doi/full/10.1080/0969594X.2022.2043240},
	doi = {10.1080/0969594X.2022.2043240},
	abstract = {Written expression curriculum-based measurement (WE-CBM) is a formative assessment approach for screening and progress mon­ itoring. To extend evaluation of WE-CBM, we compared handcalculated and automated scoring approaches in relation to the number of screening samples needed per student for valid scores, the long-term predictive validity and diagnostic accuracy of scores, and predictive and diagnostic bias for underrepresented student groups. Second- to fifth-grade students (n = 609) completed five WE-CBM tasks during one academic year and a standardised writing test in fourth and seventh grade. Averaging WE-CBM scores across multiple samples improved validity. Complex hand-calculated metrics and automated tools outperformed simpler metrics for the long-term prediction of writing performance. No evidence of bias was observed between African American and Hispanic stu­ dents. The study will illustrate the absence of test bias as necessary condition for fair and equitable screening procedures and the importance of future research to include comparisons with majority groups.},
	language = {en},
	number = {2},
	urldate = {2022-08-27},
	journal = {Assessment in Education: Principles, Policy \& Practice},
	author = {Matta, Michael and Mercer, Sterett H. and Keller-Margulis, Milena A.},
	month = mar,
	year = {2022},
	pages = {200--218},
	file = {Matta et al. - 2022 - Evaluating validity and bias for hand-calculated a.pdf:C\:\\Users\\Michael\\Zotero\\storage\\WQWTRWPU\\Matta et al. - 2022 - Evaluating validity and bias for hand-calculated a.pdf:application/pdf},
}